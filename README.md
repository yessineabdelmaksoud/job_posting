# 📊 Data Warehouse Project: Job Postings Analysis  

## 🔍 Project Description  

This project focuses on building a **data warehouse** to analyze job postings and answer key questions like:  
- How have salaries evolved over time for a particular job type?  
- What trends can be identified in job postings based on location, salary, or industry?  

To achieve this, the project integrates **multiple data sources**, implements **ETL pipelines**, and uses a **star schema model** for efficient analytics.  

---

## 🚀 Features  

- **Data Sources:**  
  - CSV files  
  - JSON files  
  - Relational databases  

- **ETL Process:**  
  1. Python-based ETL pipelines using `pyodbc` and `adodbapi` and `pandas` and `numpy`.  
  2. Azure Data Factory pipelines for scalable data integration.  

- **Data Storage:**  
  - MOLAP engine to build a multidimensional cube for advanced analytics.  

- **Visualization:**  
  - Power BI dashboards for trend analysis and interactive exploration.  



## 🔗 Data Sources  

This project uses publicly available datasets from Kaggle:  

1. https://www.kaggle.com/datasets/ravindrasinghrana/job-description-dataset

2. https://www.kaggle.com/datasets/arshkon/linkedin-job-postings

---




## 📊 Technologies Used  

- **Python**: ETL pipelines  
- **Azure Data Factory**: Scalable ETL  
- **Power BI**: Data visualization  
- **SQL**: Star schema modeling  
- **MOLAP**: Data storage for analytics  
